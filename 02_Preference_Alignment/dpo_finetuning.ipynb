{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65f1e1be",
   "metadata": {},
   "source": [
    "# Preference Alignment with Direct Preference Optimization (DPO)\n",
    "\n",
    "In Questo notebook andremo a svolgere il processo di fine-tuning di un LLM utilizzando Direct Preference Optimization (DPO). Useremo il modello **SmolLM-135M-Instruct** il qule √® gi√† affinato con il SFT Training, quindi √® compatibile per fare il DPO fine-tuning. Possiamo anche utilizzare il nostro modello affinato con SFT nel primo modulo **./01_Instruction_Tuning/SmolLM2-FT-MyDataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5017ac42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf0aa84d3c541e69fb3825e7872069f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53b79fb",
   "metadata": {},
   "source": [
    "## Carichiamo il modello affinato con SFT su HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe19ca8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ Caricamento tokenizer...\n",
      "üì§ Caricamento modello...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2911b88ab34d71b4e897a60b659b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd9910d445e644ce87a6061c281223d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/538M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modello caricato con successo su https://huggingface.co/felipe93/smolLM2-ft\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_path = \"../01_Instruction_Tuning/SmolLM2-FT-MyDataset\"\n",
    "repo_name = \"felipe93/smolLM2-ft\"  # ‚úÖ Usa il tuo username corretto\n",
    "\n",
    "# Carica tokenizer e modello\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "\n",
    "# Carica su Hugging Face Hub\n",
    "print(\"üì§ Caricamento tokenizer...\")\n",
    "tokenizer.push_to_hub(repo_name)\n",
    "print(\"üì§ Caricamento modello...\")\n",
    "model.push_to_hub(repo_name)\n",
    "\n",
    "print(f\"‚úÖ Modello caricato con successo su https://huggingface.co/{repo_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b74be9",
   "metadata": {},
   "source": [
    "# Ora carichiamo il modello dalla repo creata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "712462e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9259dccdf38847fda1d5b9c19343909b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c419e6bc8a2467d949694331448299f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785d115171784b00bd0d8f463c25eb47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2279b24f301e499486e76788ad5398b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.52M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fd29fc114e44b1abbf6d86f17ff5d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/873 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc439ab6dfa64d40a543567fc01e21f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/795 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f90f3a4694347cc82abf6cbffb4e188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/538M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc52b13d459940a591dc4a0111be48d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/139 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(49152, 576, padding_idx=2)\n",
      "    (layers): ModuleList(\n",
      "      (0-29): 30 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=576, out_features=576, bias=False)\n",
      "          (k_proj): Linear(in_features=576, out_features=192, bias=False)\n",
      "          (v_proj): Linear(in_features=576, out_features=192, bias=False)\n",
      "          (o_proj): Linear(in_features=576, out_features=576, bias=False)\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=576, out_features=1536, bias=False)\n",
      "          (up_proj): Linear(in_features=576, out_features=1536, bias=False)\n",
      "          (down_proj): Linear(in_features=1536, out_features=576, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((576,), eps=1e-05)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=576, out_features=49152, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"felipe93/smolLM2-ft\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"felipe93/smolLM2-ft\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a43462",
   "metadata": {},
   "source": [
    "## Impotiamo le librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "addbe1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "from trl import DPOTrainer, DPOConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa85f14b",
   "metadata": {},
   "source": [
    "## Carichiamo il dataset\n",
    "Usiamo il dataset [ultrafeedback_binarized](https://huggingface.co/datasets/trl-lib/ultrafeedback_binarized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48637a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c944a59d0a4a2d9fceab7786e57a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/643 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04868445423401b9ca383d5d08ec5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/131M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ad4123612145d3bc41c4cb7bad8e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/2.14M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446a510fc6104b2a8c7910440db13c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/62135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81846ead12ed47f9a1c859f40d751962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['chosen', 'rejected', 'score_chosen', 'score_rejected'],\n",
      "    num_rows: 62135\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(path=\"trl-lib/ultrafeedback_binarized\", split=\"train\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e08251f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'Use the pygame library to write a version of the classic game Snake, with a unique twist', 'role': 'user'}, {'content': \"Sure, I'd be happy to help you write a version of the classic game Snake using the pygame library! Here's a basic outline of how we can approach this:\\n\\n1. First, we'll need to set up the game display and create a game object that we can use to handle the game's state.\\n2. Next, we'll create the game's grid, which will be used to represent the game board. We'll need to define the size of the grid and the spaces within it.\\n3. After that, we'll create the snake object, which will be used to represent the player's movement. We'll need to define the size of the snake and the speed at which it moves.\\n4. We'll also need to create a food object, which will be used to represent the food that the player must collect to score points. We'll need to define the location of the food and the speed at which it moves.\\n5. Once we have these objects set up, we can start handling the game's logic. We'll need to define the rules for the player's movements, such as how the player can move the snake and how the snake will grow as the player collects more food.\\n6. We'll also need to add collisions detection to the game, so that the snake and the food can collide with each other.\\n7. Finally, we'll need to add a user interface to the game, such as a menu and a scoreboard.\\n\\nNow, as for the unique twist, we could add a few features to make the game more interesting. For example, we could add power-ups that give the player special abilities, such as the ability to grow the snake faster or to change its direction. We could also add obstacles, such as walls or pits, that the player must avoid.\\n\\nHere's some sample code to get us started:\\n```\\nimport pygame\\n\\n# Initialize pygame\\npygame.init()\\n\\n# Set up the game display\\nwidth = 800\\nheight = 600\\nscreen = pygame.display.set_mode((width, height))\\n\\n# Define the colors\\nWHITE = (255, 255, 255)\\nBLACK = (0, 0, 0)\\nGREEN = (0, 255, 0)\\n\\n# Define the game objects\\nsnake = pygame.Rect(50, 50, 10, 10)\\nfood = pygame.Rect(100, 100, 10, 10)\\n\\n# Define the game logic\\ndef update_snake():\\n    # Get the mouse position\\n    mouse_pos = pygame.mouse.get_pos()\\n\\n    # Move the snake based on the mouse position\\n    if mouse_pos[0] > snake.x:\\n        snake.x += 10\\n    elif mouse_pos[0] < snake.x:\\n        snake.x -= 10\\n    elif mouse_pos[1] > snake.y:\\n        snake.y += 10\\n    elif mouse_pos[1] < snake.y:\\n        snake.y -= 10\\n\\n    # Update the snake's size\\n    if snake.x == food.x and snake.y == food.y:\\n        snake.width += 10\\n        snake.height += 10\\n\\n# Define the game loop\\ndef game_loop():\\n    # Clear the screen\\n    screen.fill(BLACK)\\n\\n    # Update the game objects\\n    update_snake()\\n\\n    # Draw the game objects\\n    screen.fill(WHITE)\\n    screen.draw.rect(snake, GREEN)\\n    screen.draw.rect(food, BLACK)\\n\\n    # Update the display\\n    pygame.display.flip()\\n\\n# Start the game loop\\ngame_loop()\\n\\n# Run the game\\nwhile True:\\n    for event in pygame.event.get():\\n        if event.type == pygame.QUIT:\\n            pygame.quit()\\n            break\\n\\n    pygame.time.Clock().tick(60)\\n```\\nThis code sets up a basic game display, defines the snake and food objects, and updates the game state based on the player's movements. We've also added a simple user interface and some basic collision detection.\\n\\nAs for the unique twist, we could add a few features to make the game\", 'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0]['chosen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23487dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'Use the pygame library to write a version of the classic game Snake, with a unique twist', 'role': 'user'}, {'content': 'Sure, here\\'s an example of how to write a version of Snake game with a unique twist using the Pygame library:\\n```python\\nimport pygame\\n\\nclass SnakeGame:\\n    def __init__(self, game_width, game_height):\\n        pygame.init()\\n        screen = pygame.display.set_mode((game_width, game_height))\\n        pygame.display.set_caption(\"Snake Game\")\\n        self.speed = 5  # Speed of the snake\\n        self.food_speed = 1  # Speed of the food\\n        self.direction = 0  # Initial direction of the snake\\n        self.snakelen = 0  # Length of the snake\\n        self.food = pygame.image.load(\"snake_food.png\")\\n        self.head = pygame.image.load(\"snake_head.png\")\\n        self.tail = pygame.image.load(\"snake_tail.png\")\\n        self.game Quint()\\n    def Quint(self):\\n        for i in range(50):\\n            pygame.draw.line(screen, (180, 100, 220), (0, 0, 200), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (50, 0, 200), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (50, 50, 200), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (50, 50, 300), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (50, 80, 200), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (50, 80, 300), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (0, 50, 200), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (0, 50, 300), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (0, 80, 200), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (0, 80, 300), 2)\\n            pygame.display.flip()\\n        self.game.run()\\n    def run(self):\\n        while True:\\n            for event in pygame.event. pygame.KEYDOWN:\\n                if event.key == pygame.K_LEFT:\\n                    self.direction = -1\\n                if event.key == pygame.K_RIGHT:\\n                    self.direction = 1\\n            self.snakelen += 1\\n            if self.snakelen == 0:\\n                self.snakelen = 10\\n            if self.snakelen > 20:\\n                self.snakelen = 20\\n            self.gameQuint()\\n            self.foodCrossing()\\n            self.headRun()\\n            pygame.display.update()\\ngame = SnakeGame(800, 600)\\ngame.run()\\n```\\nIn this game, the snake moves with a constant speed, but the direction of the snake can be controlled by the user using the left and right arrow keys. The snake grows in length every 10 segments, and when it reaches a certain length, it resets to 10 segments. The food moves fast and randomly crosses the screen, and the snake can eat it by colliding with it. The snake\\'s head and tail move independently of each other. The game ends when the snake dies or reaches the end of the screen.', 'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0]['rejected'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a600d470",
   "metadata": {},
   "source": [
    "Come vediamo il dataset ha due colonne **chosen** e **rejected** dove per la stessa richiesta vi sono le due risposte una corretta e l'altra no, come il modello non deve rispondere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c790cdb0",
   "metadata": {},
   "source": [
    "## Selezioniamo il nostro modello\n",
    "\n",
    "Usiamo il nostro modello affinato con SFT partendo dal modello base **SmolLM-135M**, il quale √® gi√† adatto per DPO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6be2bcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"felipe93/SmolLM2-ft\"\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name,\n",
    "    torch_dtype=torch.float32\n",
    ").to(device)\n",
    "# ogni passo (token generato non usa K-V dell'attenzione degli stati precedenti) viene ricalcolato da zero\n",
    "model.config.use_cache = False\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# token di padding (di fine sequenza)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Impostiamo il notro nome per il modello affinato \n",
    "finetune_name = \"SmolLM2-FT-DPO\"\n",
    "finetune_tags = [\"smol-course\", \"module_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a158e9",
   "metadata": {},
   "source": [
    "## Addestriamo il modello con DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c23de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Arguments\n",
    "training_args = DPOConfig(\n",
    "    #training batch size per GPU\n",
    "    per_device_train_batch_size=4,\n",
    "    # Number of updates steps to accumulate before performing a backward/update pass\n",
    "    # Effective batch size = per_device_train_batch_size * gradient_accumulation_steps\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    learning_rate=5e-5,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    max_steps=200,\n",
    "    save_strategy='no',\n",
    "    logging_steps=1,\n",
    "    output_dir=\"smol_dpo_output\",\n",
    "    warmup_steps=100,\n",
    "    bf16=True,\n",
    "    report_to='none',\n",
    "    remove_unused_columns=False,\n",
    "    hub_model_id=finetune_name,\n",
    "    beta=0.1,\n",
    "    max_prompt_length=1024,\n",
    "    max_length=1536\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d1a1b0",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è PARAMETRI BASE DI TRAINING\n",
    "\n",
    "### ‚úÖ `per_device_train_batch_size=4`\n",
    "\n",
    "> Numero di esempi (prompt + chosen + rejected) elaborati in parallelo **su ogni GPU o dispositivo**.\n",
    "\n",
    "* Se hai 1 GPU, √® la batch size effettiva per ogni step.\n",
    "* L'**effective batch size totale** viene calcolato insieme a `gradient_accumulation_steps`.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ `gradient_accumulation_steps=4`\n",
    "\n",
    "> Quanti step **accumulare i gradienti prima** di eseguire l‚Äôottimizzazione.\n",
    "\n",
    "* In pratica, fa finta di avere `4 √ó 4 = 16` batch size totale, senza saturare la memoria GPU.\n",
    "* Consente di addestrare con **batch virtuali pi√π grandi**, utile con modelli pi√π grandi o GPU piccole.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ `gradient_checkpointing=True`\n",
    "\n",
    "> Abilita il salvataggio di memoria **ricostruendo gli attivatori** durante il backward pass.\n",
    "\n",
    "* ‚úÖ Pro: Riduce molto il consumo di RAM/VRAM\n",
    "* ‚ùå Contro: Rallenta un po‚Äô il training\n",
    "* Molto utile su modelli da 1B+ parametri o su hardware con meno di 24 GB VRAM\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ `learning_rate=5e-5`\n",
    "\n",
    "> Tasso base di apprendimento, ovvero **quanto il modello cambia** per ogni passo di ottimizzazione.\n",
    "\n",
    "* 5e-5 √® una scelta abbastanza \"sicura\" per modelli piccoli o SFT/DPO leggeri\n",
    "* Si combina con il learning rate scheduler\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ `lr_scheduler_type=\"cosine\"`\n",
    "\n",
    "> Il learning rate **diminuisce seguendo una curva coseno**, che lo porta a zero in modo graduale.\n",
    "\n",
    "* Particolarmente utile per il fine-tuning: **inizia alto, poi si stabilizza, poi si spegne dolcemente**\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ `max_steps=200`\n",
    "\n",
    "> Numero massimo di step di training (update steps).\n",
    "\n",
    "* **Non sono epoch**: ogni step √® un batch ottimizzato.\n",
    "* Se usi un dataset piccolo o bassa batch size, pu√≤ bastare anche < 1000 step.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ `save_strategy=\"no\"`\n",
    "\n",
    "> Disabilita completamente il **salvataggio automatico dei checkpoint** durante il training.\n",
    "\n",
    "* Pi√π leggero ma rischioso se il training si interrompe.\n",
    "* Puoi aggiungere manualmente `trainer.save_model()` a fine training.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ `logging_steps=1`\n",
    "\n",
    "> Ogni quanti step vengono **loggate le metriche** (loss, lr, ecc.).\n",
    "\n",
    "* `1` = logga ad ogni step, utile per debug o esperimenti brevi.\n",
    "* In produzione o per esperimenti lunghi si usa spesso `10`, `50`, `100`.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ `output_dir=\"smol_dpo_output\"`\n",
    "\n",
    "> Directory in cui **verr√† salvato il modello finale** dopo il training.\n",
    "\n",
    "* Contiene anche tokenizer e config aggiornati.\n",
    "* Se esiste gi√†, verr√† sovrascritta a meno che tu non usi `resume_from_checkpoint`.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ `warmup_steps=100`\n",
    "\n",
    "> I primi 100 step di training usano **learning rate crescente da 0 a `learning_rate`**.\n",
    "\n",
    "* Stabilizza l‚Äôottimizzazione all'inizio.\n",
    "* Consigliato per DPO e fine-tuning delicati.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ `bf16=True`\n",
    "\n",
    "> Usa la **precisione bfloat16** (se supportata da hardware).\n",
    "\n",
    "* Richiede GPU **Ampere+** (es. A100, RTX 30xx).\n",
    "* Risparmia VRAM e accelera il training senza perdita di qualit√†.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ `report_to=\"none\"`\n",
    "\n",
    "> Disabilita la loggatura su strumenti esterni (come `wandb`, `tensorboard` ecc.)\n",
    "\n",
    "* Evita errori se non hai configurato nulla.\n",
    "* Se vuoi usare `wandb`, metti `\"wandb\"` e imposta `WANDB_API_KEY`.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ `remove_unused_columns=False`\n",
    "\n",
    "> Mantiene **tutti i campi nel dataset**, anche quelli non usati nel forward.\n",
    "\n",
    "* ‚ö†Ô∏è `True` potrebbe eliminare campi come `rejected`, `chosen` o `prompt`.\n",
    "* `False` √® **necessario** per DPO, perch√© servono pi√π campi rispetto a SFT.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ `use_mps_device=device == \"mps\"`\n",
    "\n",
    "> Abilita l‚Äôuso del backend **Metal Performance Shaders** (solo per Mac con Apple Silicon).\n",
    "\n",
    "* Se `device == \"mps\"` allora abilita ottimizzazioni per GPU Apple.\n",
    "* Non ha effetto su CUDA/CPU.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ `hub_model_id=finetune_name`\n",
    "\n",
    "> Specifica il nome del modello su Hugging Face Hub da usare durante l'upload automatico.\n",
    "\n",
    "* Esempio: `\"felipe93/smolLM2-dpo\"`\n",
    "* Verr√† usato da `.push_to_hub()` o `trainer.push_to_hub()` se chiamato dopo il training.\n",
    "\n",
    "---\n",
    "\n",
    "## üî• PARAMETRI SPECIFICI DI DPO\n",
    "\n",
    "### ‚úÖ `beta=0.1`\n",
    "\n",
    "> Temperatura che **modula la loss DPO**: quanto il modello dovrebbe preferire la risposta ‚Äúchosen‚Äù rispetto alla ‚Äúrejected‚Äù.\n",
    "\n",
    "* Valori bassi (0.05‚Äì0.1) = **modello pi√π cauto**, preferisce con pi√π certezza solo output chiaramente superiori\n",
    "* Valori alti (0.5‚Äì1.0) = modello pi√π ‚Äúaggressivo‚Äù, cambia facilmente\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ `max_prompt_length=1024`\n",
    "\n",
    "> Lunghezza massima del prompt (input dell‚Äôutente) in token.\n",
    "\n",
    "* Serve per troncamento e padding.\n",
    "* Evita crash su modelli piccoli (come `SmolLM-135M`) che non supportano prompt lunghi.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ `max_length=1536`\n",
    "\n",
    "> Lunghezza massima totale (prompt + output generato) in token.\n",
    "\n",
    "* DPO valuta l‚Äôintero output generato rispetto al prompt.\n",
    "* Deve essere < `model.config.max_position_embeddings` (tipicamente 2048 o 4096).\n",
    "\n",
    "---\n",
    "\n",
    "## üß† In sintesi\n",
    "\n",
    "Questo blocco di configurazione √® ottimizzato per:\n",
    "\n",
    "‚úÖ Allenare un **modello Instruct di piccole dimensioni** con DPO\n",
    "‚úÖ Su hardware limitato (es. 1 GPU, M1/M2 Mac)\n",
    "‚úÖ Con preferenza per velocit√†, leggerezza e portabilit√†\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6446fc",
   "metadata": {},
   "source": [
    "## üß† Cos'√® `gradient_checkpointing`?\n",
    "\n",
    "In un training classico, **durante il forward pass** (cio√® quando il modello elabora l‚Äôinput), vengono salvati **tutti i tensori intermedi** (attivazioni) per poterli usare poi nel **backward pass** (cio√® quando si calcolano i gradienti per fare l‚Äôottimizzazione).\n",
    "\n",
    "Questi tensori possono occupare **molta memoria**, soprattutto con modelli grandi o prompt lunghi.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Con `gradient_checkpointing=True`\n",
    "\n",
    "üëâ Il modello **NON salva le attivazioni intermedie durante il forward**.\n",
    "\n",
    "üìå Invece, **le ricalcola dinamicamente durante il backward**, al momento in cui servono per calcolare i gradienti.\n",
    "\n",
    "> √à come dire: \"non salvo tutto subito, ma quando mi serve, lo ricalcolo\".\n",
    "\n",
    "---\n",
    "\n",
    "## üìâ Differenza visiva\n",
    "\n",
    "|             | üß† Normal Training             | üß† Gradient Checkpointing     |\n",
    "| ----------- | ------------------------------ | ----------------------------- |\n",
    "| Memoria GPU | Alta (tutti i tensori salvati) | Bassa (salvati solo pochi)    |\n",
    "| Velocit√†    | Veloce                         | Pi√π lento (perch√© ricalcola)  |\n",
    "| Adatto a    | GPU grandi o modelli piccoli   | GPU limitate o modelli grandi |\n",
    "\n",
    "---\n",
    "\n",
    "## üìà Esempio numerico\n",
    "\n",
    "Immagina di addestrare un modello con 1.3B parametri su una GPU da 12 GB:\n",
    "\n",
    "* üîÅ Senza `gradient_checkpointing`: crasha per mancanza di memoria\n",
    "* ‚úÖ Con `gradient_checkpointing=True`: funziona, ma impiega 20‚Äì30% di tempo in pi√π\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Compatibilit√† e attenzione\n",
    "\n",
    "* Funziona con quasi tutti i modelli **Transformer-based** (es. GPT, BERT, Falcon, LLaMA, ecc.)\n",
    "* Alcune librerie (es. `DeepSpeed`, `accelerate`, `bitsandbytes`) lo richiedono o lo abilitano di default\n",
    "* Pu√≤ interferire con `use_cache=True` ‚Üí spesso si disattiva `use_cache` quando lo si usa\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Quando usarlo?\n",
    "\n",
    "| Caso                                                 | Lo uso?                        |\n",
    "| ---------------------------------------------------- | ------------------------------ |\n",
    "| Modello < 500M su GPU da 24 GB                       | ‚ùå No                           |\n",
    "| Modello da 1B+ o prompt lunghi su 12‚Äì16 GB VRAM      | ‚úÖ S√¨                           |\n",
    "| Addestramento su Apple M1/M2 (8‚Äì16 GB RAM condivisa) | ‚úÖ S√¨                           |\n",
    "| Deployment/inference                                 | ‚ùå No (rallenta senza benefici) |\n",
    "\n",
    "---\n",
    "\n",
    "## üîÅ In pratica\n",
    "\n",
    "```python\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"felipe93/smolLM2-ft\")\n",
    "model.gradient_checkpointing_enable()\n",
    "```\n",
    "\n",
    "Oppure:\n",
    "\n",
    "```python\n",
    "training_args = TrainingArguments(\n",
    "    ...\n",
    "    gradient_checkpointing=True,\n",
    "    ...\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üß† In sintesi\n",
    "\n",
    "| ‚úÖ Vantaggi                     | ‚ùå Svantaggi                       |\n",
    "| ------------------------------ | --------------------------------- |\n",
    "| Usa molta meno memoria GPU     | Pi√π lento (ricalcola attivazioni) |\n",
    "| Permette batch pi√π grandi      | Debug pi√π difficile               |\n",
    "| Essenziale su hardware modesto | Aumenta il tempo per ogni step    |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acc4f07",
   "metadata": {},
   "source": [
    "## üß† Cos'√® `beta` in DPO?\n",
    "\n",
    "Nel DPO, il modello √® addestrato su **coppie di risposte**:\n",
    "\n",
    "* `prompt` ‚Üí una **risposta preferita** (`chosen`)\n",
    "* `prompt` ‚Üí una **risposta rifiutata** (`rejected`)\n",
    "\n",
    "L‚Äôobiettivo √® far s√¨ che il modello assegni **una probabilit√† pi√π alta alla risposta preferita**, rispetto alla rifiutata.\n",
    "\n",
    "---\n",
    "\n",
    "## üìê Formula semplificata della loss DPO\n",
    "\n",
    "```text\n",
    "L = -log(œÉ(Œ≤ √ó (log p(chosen) - log p(rejected))))\n",
    "```\n",
    "\n",
    "Dove:\n",
    "\n",
    "* `œÉ` √® la **funzione sigmoide**\n",
    "* `log p(chosen)` √® il log-likelihood della risposta preferita\n",
    "* `log p(rejected)` √® quello della risposta rifiutata\n",
    "* **`Œ≤` √® il moltiplicatore della differenza**, ovvero **quanto peso dare alla preferenza**\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Cosa fa `beta` in pratica?\n",
    "\n",
    "* Se `Œ≤` √® **grande** ‚Üí anche piccole differenze tra `chosen` e `rejected` causano **grandi aggiornamenti**\n",
    "* Se `Œ≤` √® **piccolo** ‚Üí il modello sar√† **pi√π cauto**, cambia solo se la differenza √® chiara\n",
    "\n",
    "---\n",
    "\n",
    "## üéõÔ∏è Effetto dei valori di `beta`\n",
    "\n",
    "| `beta` | Effetto sul modello                               | Quando usarlo                        |\n",
    "| ------ | ------------------------------------------------- | ------------------------------------ |\n",
    "| `1.0`  | Forte spinta a preferire le risposte `chosen`     | Quando il dataset √® molto pulito     |\n",
    "| `0.5`  | Moderata sensibilit√†                              | Default bilanciato                   |\n",
    "| `0.1`  | Comportamento **cauto**, solo preferenze evidenti | ‚úÖ Consigliato per SFT + DPO          |\n",
    "| `0.01` | Quasi nessuna influenza (molto conservativo)      | Per test, debugging o low-signal DPO |\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Esempio intuitivo\n",
    "\n",
    "Immagina queste log-probabilit√†:\n",
    "\n",
    "```text\n",
    "log p(chosen)   = -1.2\n",
    "log p(rejected) = -1.5\n",
    "```\n",
    "\n",
    "Differenza = 0.3\n",
    "\n",
    "### Con Œ≤=1.0:\n",
    "\n",
    "```text\n",
    "œÉ(1.0 √ó (0.3)) ‚âà 0.57 ‚Üí Loss ‚âà -log(0.57) ‚âà 0.56\n",
    "```\n",
    "\n",
    "### Con Œ≤=0.1:\n",
    "\n",
    "```text\n",
    "œÉ(0.1 √ó (0.3)) ‚âà 0.51 ‚Üí Loss ‚âà -log(0.51) ‚âà 0.67\n",
    "```\n",
    "\n",
    "‚û°Ô∏è Il **gradiente sar√† pi√π piccolo** ‚Üí aggiornamenti pi√π morbidi\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Quale valore usare?\n",
    "\n",
    "* Per modelli piccoli o dataset rumorosi ‚Üí **`beta=0.1`** (come nel tuo caso)\n",
    "* Per dataset molto curati (es. `HH-RLHF`) o DPO finale su modello robusto ‚Üí `0.5` o `1.0`\n",
    "* In fase di debug o esperimenti ‚Üí prova anche `0.01` per vedere se il modello sta apprendendo\n",
    "\n",
    "---\n",
    "\n",
    "## üìå In sintesi\n",
    "\n",
    "| Aspetto     | `beta` controlla...                                           |\n",
    "| ----------- | ------------------------------------------------------------- |\n",
    "| Intensit√†   | Quanto fortemente il modello segue le preferenze              |\n",
    "| Sensibilit√† | A che punto una differenza √® considerata rilevante            |\n",
    "| Stabilit√†   | Valori pi√π bassi rendono il training pi√π stabile              |\n",
    "| Overfitting | Valori alti possono portare a overfit se i dati sono rumorosi |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bbd9523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../01_Instruction_Tuning/SmolLM2-FT-MyDataset\\\\tokenizer_config.json',\n",
       " '../01_Instruction_Tuning/SmolLM2-FT-MyDataset\\\\special_tokens_map.json',\n",
       " '../01_Instruction_Tuning/SmolLM2-FT-MyDataset\\\\vocab.json',\n",
       " '../01_Instruction_Tuning/SmolLM2-FT-MyDataset\\\\merges.txt',\n",
       " '../01_Instruction_Tuning/SmolLM2-FT-MyDataset\\\\added_tokens.json',\n",
       " '../01_Instruction_Tuning/SmolLM2-FT-MyDataset\\\\tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template = \"\"\"{% for message in messages %}{{ '<|im_start|>' + message['role'] + '\\\\n' + message['content'] + '<|im_end|>\\\\n' }}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\\\n' }}{% endif %}\"\"\"\n",
    "\n",
    "tokenizer.chat_template = chat_template\n",
    "tokenizer.save_pretrained(\"../01_Instruction_Tuning/SmolLM2-FT-MyDataset\")  # oppure altra cartella tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd590b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccfee1fdd87c4146af47b2c07a945bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/62135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e22933265c4092abb4299adf7549e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/62135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = DPOTrainer(\n",
    "    # The model to be trained\n",
    "    model=model,\n",
    "    # Training configuration from above\n",
    "    args=training_args,\n",
    "    # Dataset containing preferred/rejected response pairs\n",
    "    train_dataset=dataset,\n",
    "    # Tokenizer for processing inputs\n",
    "    processing_class=tokenizer,\n",
    "    # DPO-specific temperature parameter that controls the strength of the preference model\n",
    "    # Lower values (like 0.1) make the model more conservative in following preferences\n",
    "    # beta=0.1,\n",
    "    # Maximum length of the input prompt in tokens\n",
    "    # max_prompt_length=1024,\n",
    "    # Maximum combined length of prompt + response in tokens\n",
    "    # max_length=1536,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02196f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\felip\\Desktop\\smol-course\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\felip\\Desktop\\smol-course\\.venv\\lib\\site-packages\\transformers\\trainer.py:3700: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  ctx_manager = torch.cpu.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 49:42:39, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.709100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.716900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.691900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.686800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.699100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.681300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.670200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.674700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.658700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.669700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.691400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.676300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.668700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.682600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.671700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.654400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.634800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.655500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.735100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.697600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.615000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.623000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.692600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.695200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.699500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.694100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.690100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.633300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.705600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.664600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.623400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.518600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.823900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.670600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.602300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.726800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.586200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.761200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.634500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.690400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.688700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.524900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.598200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.513900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.585600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.609300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.707500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.791000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.813000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.646200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.731800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.743000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.707100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.567200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.666700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.733100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.637300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.683300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.574100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.657900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.732800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.636000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.802800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.894200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.704300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.633700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.719300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.765900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.591800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.684700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.830800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.581200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.580100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.541100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.470800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.893300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>1.203100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.729100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.950200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.855100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.543100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.779100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.604000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.729400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.818100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.702400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.725100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.766100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.596200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.762200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.566300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.703300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.741000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.543100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.433800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.697900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.648900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.970700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.558800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.695300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.913000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.683600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.748000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.595500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.679100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.708400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.472600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.829400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.611500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>1.009200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.621600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.875900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.920800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.650800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.804300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.841800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.836400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.698000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.769500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.933200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.719700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.731300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0.914300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.749500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>0.551600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.528600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>0.657600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.877600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.585600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>1.015300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.717700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.350300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>0.983200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.834700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.455100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.785000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>0.858300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.691100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>0.731400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.552500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.507200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.582300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>1.006500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.685700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.849200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.553800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>0.784400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.497200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>0.714500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>0.747000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.663900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>0.649600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>0.448400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.599500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>0.702800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.698000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.689700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>1.307600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>0.654100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.644400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>0.626100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>0.856200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.910900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>0.688900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.779900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.614000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>1.355300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>0.578400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>0.650900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.704100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.488800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>0.677500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>0.454800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>0.690400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.517500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>0.413800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>0.686400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>0.705400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>1.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0.812600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>0.530200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>0.753600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>0.522500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>0.730900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.715000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>0.842600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.579300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>0.775400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>0.474800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.595100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>0.737300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>0.729600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>0.692200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>0.540600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.985000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the model\n",
    "trainer.save_model(f\"./{finetune_name}\")\n",
    "\n",
    "# Save to the huggingface hub if login (HF_TOKEN is set)\n",
    "if os.getenv(\"HF_TOKEN\"):\n",
    "    trainer.push_to_hub(tags=finetune_tags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
