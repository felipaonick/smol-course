# ğŸ§  Instruction Tuning di Language Models

ğŸ“š Modulo: Instruction Tuning
ğŸ¯ Obiettivo: Adattare modelli linguistici pre-addestrati a task specifici tramite dati supervisionati e strutture conversazionali (chat templates).

---

## ğŸ“Œ Cosâ€™Ã¨ lâ€™Instruction Tuning?

* Ãˆ il processo di **adattamento di un modello LLM pre-addestrato** a specifici compiti.
* Si realizza tramite:

  1. **Chat Templates** â€“ strutturazione dellâ€™interazione AI-utente
  2. **Supervised Fine-Tuning (SFT)** â€“ addestramento supervisionato con dataset etichettati

---

## 1ï¸âƒ£ Chat Templates

### ğŸ“‹ Definizione

* Template che strutturano il dialogo tra utenti e modelli AI.
* Utili per:

  * Assicurare **consistenza** e **contestualitÃ ** nelle risposte
  * Allineare lâ€™output a **formati strutturati** come `chatml`

### ğŸ§± Componenti tipici

* **System prompt**: definisce il comportamento del modello
* **Role-based messages**: suddivisione dei messaggi tra `user`, `assistant`, `system`

### ğŸ§ª Esercizi pratici (notebook)

| Esercizio                                       | Obiettivo |
| ----------------------------------------------- | --------- |
| ğŸ¢ Converti `HuggingFaceTB/smoltalk` â†’ `chatml` |           |
| ğŸ• Converti `openai/gsm8k` â†’ `chatml`           |           |

ğŸ”— **Notebook**: chat_templates.ipynb

---

## 2ï¸âƒ£ Supervised Fine-Tuning (SFT)

### âš™ï¸ Definizione

* Addestramento supervisionato di un LLM su **dataset etichettati per un task specifico**.
* Obiettivo: migliorare la performance del modello sul task target.

### ğŸªœ Fasi principali

1. Scelta del dataset (es. `smoltalk`, `the-stack-smol`)
2. Conversione in formato `chatml` (se necessario)
3. Utilizzo di `SFTTrainer` (es. da `trl`) per eseguire il fine-tuning
4. Valutazione delle performance e iterazione

### ğŸ§ª Esercizi pratici (notebook)

| Esercizio                                    | Obiettivo |
| -------------------------------------------- | --------- |
| ğŸ¢ SFT su `HuggingFaceTB/smoltalk`           |           |
| ğŸ• SFT su `bigcode/the-stack-smol`           |           |
| ğŸ¦ Scegli un dataset per un caso dâ€™uso reale |           |

ğŸ”— **Notebook**: sft_finetuning.ipynb

---

## ğŸ”— Risorse e riferimenti

* ğŸ“˜ [Transformers documentation on chat templates](https://huggingface.co/docs/transformers/chat_templating)
* ğŸ§ª [Script per SFT in TRL](https://github.com/huggingface/trl)
* ğŸ§  [`SFTTrainer` in TRL](https://huggingface.co/docs/trl/main/en/sft_trainer)
* ğŸ“„ [Paper su Direct Preference Optimization](https://arxiv.org/abs/2305.18290)
* ğŸ“ [Guida SFT con TRL](https://huggingface.co/blog/fine-tune-trl)
* ğŸ¤– [Fine-tune Google Gemma con ChatML e TRL](https://huggingface.co/blog/fine-tune-gemma)
* ğŸŒ [Fine-tuning LLM per cataloghi JSON in persiano](https://huggingface.co/blog/fine-tune-llm-json-persian)

---

âœ… *Instruction tuning Ã¨ una componente fondamentale per costruire applicazioni LLM specializzate, affidabili e allineate agli obiettivi utente. Chat templates + SFT = pipeline robusta.*

